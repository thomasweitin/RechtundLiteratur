{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a0dfb0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h1><center>Analyse der Word Embedding Modelle des Neuen Pitaval (1842-1890) </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2395d9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Das Jupyter Notebook führt Analysen mit vortrainierten Word Embedding Modellen des *Neuen Pitaval* durch und erstellt anschließend Abbildung 8 (sowie Anhang 3 und 4).\n",
    "\n",
    "### Ordnerstruktur\n",
    "####      modelle (enthält bereits erstellte Modelle)\n",
    "####      results (werden automatisch erstellt)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba0904b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## 0. Laden der benötigten Bibliotheken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935aa36a",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Word Embedding\n",
    "from gensim.models import word2vec\n",
    "import pickle\n",
    "\n",
    "# Visualisierung\n",
    "%matplotlib notebook\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926891d2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dateipfade anpassen\n",
    "path_modelle = r\"...\\modelle\"\n",
    "path_results = r\"...\\results\"\n",
    "\n",
    "os.chdir(path_modelle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4073f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Einlesen der Modelle und Daten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad720383-3b92-4f29-b617-f45efd33a9a3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Für die Analysen des *Neuen Pitaval* wurden insgesamt drei Word Embedding Modelle erstellt. Ein Modell für den gesamten Zeitraum (1842-1890) und jeweils ein Modell für den Zeitraum der Herausgeberschaft unter Julius Eduard Hitzig und Wilhelm Häring (Willibald Alexis) (Band 1-30 bzw. 1842-1862) sowie unter Anton Vollert (Band 31-60 bzw. 1862-1890). Das gesamte Korpus umfasst (nach dem Preprocessing) 6.720.771 Token, die einzelnen Teilkorpora jeweils 3.577.314 und 3.143.457 Token.\n",
    "\n",
    "Die Word Embedding Modelle basieren auf Word2Vec (Mikolov et al. 2013) und dessen Implementierung im Python-Package *gensim*. Im Preprocessing wurden Satzzeichen entfernt, alle Wörter lemmatisiert (mit dem Package *spacy*) und kleingeschrieben. Die Modelle wurden mit den folgenden Parametern erstellt: Größe der Vektoren = 300, Größe des Kontextfensters = 5, mind. Häufigkeit der Zielwörter = 10, Architektur = Skipgram, Iterationen = 50. Daraus resultieren ein gesamtes Modell zu 22.805 Types sowie die Teilkorpora zu 14.922 Types (Hitzig/Häring) und 14.506 Types (Vollert).\n",
    "\n",
    "Die Analysen im Artikel beziehen sich auf das Gesamtkorpus (*modelPitaval*), die Modelle der Teilkorpora können für vergleichende und weiterführende Analysen genutzt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd73bb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Einlesen der Modelle\n",
    "\n",
    "modelPitaval = word2vec.KeyedVectors.load('modelPitaval_vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b4908",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelHaering = word2vec.KeyedVectors.load('modelHaering_vectors.kv')\n",
    "\n",
    "modelVollert = word2vec.KeyedVectors.load('modelVollert_vectors.kv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e89c70",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Einlesen der Korpora (in ihrer Version nach dem Preprocessing)\n",
    "\n",
    "with open('corpusPitaval_words.pkl', 'rb') as f:\n",
    "    corpusPitaval = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88331b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('corpusHaering_words.pkl', 'rb') as f:\n",
    "    corpusHaering = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75138b47",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('corpusVollert_words.pkl', 'rb') as f:\n",
    "    corpusVollert = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26628db1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Informationen zu Modellen und Korpora anzeigen\n",
    "\n",
    "print(\"Größe des Modells: \" + str(len(modelPitaval)) + \" Types, Größe des Korpus: \" + str(len(corpusPitaval)) + \" Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8506ea7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Größe des Modells: \" + str(len(modelHaering)) + \" Types, Größe des Korpus: \" + str(len(corpusHaering)) + \" Tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b694df",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Größe des Modells: \" + str(len(modelVollert)) + \" Types, Größe des Korpus: \" + str(len(corpusVollert)) + \" Tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6702b4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Visualisierungen einer Auswahl von Wörtern auf einer bestimmten Ebene"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47e0b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Der nachfolgende Code stellt dar, wie eine Gruppe von Straftaten sich in ihrer Wertigkeit auf durch Wortpaare aufgespannte Achsen verhält. Die x-Achse wird dabei immer von dem paar \"Verbrechen\"<->\"Vergehen\" bestimmt. Die y-Achse wird variiert.\n",
    "Folgende Paare werden untersucht: \"Verbrecher\" <-> \"Verbrecherin\", \"gut\" <-> \"böse\", \"Mann\" <-> \"Frau\", \"Herr\" <-> \"Dame\", \"Thäter\" <-> \"Thäterin\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bfda03",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Quelle: Gergely Nemeth, https://colab.research.google.com/drive/1TCgnpIwsr6uK4cP0Gk1RCCQrFy6s3Xc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508b783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ergebnisordner erstellen\n",
    "path_results = path_results + r\"\\WordEmbeddings\"\n",
    "\n",
    "if os.path.exists(path_results) == False:\n",
    "    os.mkdir(path_results)\n",
    "\n",
    "os.chdir(path_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8cbdcb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Liste der Wortpaare, die die y-Achse aufspannen\n",
    "wordpairs = [(\"verbrecher\", \"verbrecherin\"), (\"böse\", \"gut\"), (\"mann\", \"frau\"), (\"herr\", \"dame\"), (\"thäter\", \"thäterin\"), (\"gut\", \"böse\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcac3357",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Bestimmen des zu untersuchenden Wortpaares (0: \"verbrecher\" <-> \"verbrecherin\", 1: \"böse\" <-> \"gut\", 2: \"mann\" <-> \"frau\", 3: \"herr\" <-> \"dame\", 4: \"thäter\" <-> \"thäterin\", 5: \"gut\" <-> \"böse\")\n",
    "n = 0  \n",
    "# n = 1\n",
    "# n = 2\n",
    "# n = 3\n",
    "# n = 4\n",
    "# n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0364446",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wortlistenerstellung (W1), die ersten vier Wörter beschreiben die Achsen, die nachfolgenden die Zielwörter\n",
    "Wl = ['verbrechen', 'vergehen', wordpairs[n][1], wordpairs[n][0], 'mord', 'brandstiftung', 'diebstahl', 'einbruch', 'betrug', 'veruntreuung', 'fälschung', 'giftmord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd69e0",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Die Vektoren (Embeddings) jedes Wortes aus der Liste W1 werden in einer weiteren Liste Wv abgespeichert \n",
    "Wv = []\n",
    "for word in Wl:\n",
    "    Wv.append(modelPitaval.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed4523",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Berechnen der Differenzvektoren zwischen den Embeddings der jeweiligen Wörter, die die Achsen bilden sollen\n",
    "# Daraus wird die neue Basis gebildet\n",
    "b1 = (Wv[1]-Wv[0])\n",
    "b2 = (Wv[3]-Wv[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79351f51",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Wir wollen die Vektoren auf einen zweidimensionalen Vektorraum mit Basis (1,0) und (0,1) projezieren\n",
    "# Da B.T (1,0) = b1 und B.T (0,1) = b2, müssen wir wir für jeden Vektor v in Wv folgendes Gleichungssystem lösen: B.T x = v\n",
    "# Da B.T nicht quadratisch und nicht invertierbar ist, nähern wir die Lösung mit einer Pseudoinversen Matrix an\n",
    "#  \n",
    "#\n",
    "# Konvertieren der Liste der Wortvektoren in ein numpy-Array\n",
    "W = np.array(Wv)\n",
    "# Erstellen einer Matrix B aus den Basisvektoren b1 und b2\n",
    "B = np.array([b1,b2])\n",
    "# Berechnen der Pseudoinversen der Transponierten der Matrix B\n",
    "Bi = np.linalg.pinv(B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a4323",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Multiplizieren der Pseudoinversen Bi mit der Matrix, die die Wortvektoren enthält \n",
    "# Wp ist eine 2xn-Matrix die alle projezierten, zweidimensionalen Wortvektoren enthält\n",
    "Wp = np.matmul(Bi,W.T)\n",
    "# Wir verschieben die definierten Achsen auf die x- und y-Achse\n",
    "# Dafür subtrahieren wir komponentenweise auf der x-Achse den x-Wert der aufgespannten vertikalen Achse (Wp[0,2]), sowie auf der y-Achse den y-Wert der aufgespannten waagerechten Achse (Wp.[1,0]) \n",
    "Wp = (Wp.T-[Wp[0,2],Wp[1,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f26b7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Grafik: Scatter-Plot, Visualisierung der projezierten Vektoren\n",
    "# Jeder Punkt ist beschriftet und stellt ein Wort aus der Liste dar\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.axvline()\n",
    "plt.axhline()\n",
    "plt.scatter(Wp[0,:], Wp[1,:])\n",
    "rX = max(Wp[0,:])-min(Wp[0,:])\n",
    "rY = max(Wp[1,:])-min(Wp[1,:])\n",
    "eps = 0.005\n",
    "for i, txt in enumerate(Wl):\n",
    "    plt.annotate(txt, (Wp[0,i]+rX*eps, Wp[1,i]+rX*eps))\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"sem_scale_\" + W1[3] + \"-\" + W1[2] + \".png\", format='png', dpi=150, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
